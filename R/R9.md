# R

## 추정과 검정

- 모집단으로부터 추출된 표본으로부터 모수와 관련된 통계량(statistics)들의 값을 계산하고, 이것을 이용하여 모집단의 특성(모수)을 알아내는 과정
- 모집단으로부터 추출한 표본으로부터 얻은 정보를 이용하여 모집단의 특성을 나타내는 값을 확률적으로 추측하는 추정(estimation)
- 유의수준과 표본의 검정 통계량을 비교하여 통계적 가설의 진위를 입증하는 가설 검정(hypotheses testing)





### 점추정

- 하나의 값을 제시하여 모두의 참값을 추측



### 구간추정

- 하한값과 상한값의 신뢰구간을 지정하여 모수의 참값을 추정하는 방식



![1568853393821](assets/1568853393821.png)



- 점 추정은 하나의 값과 표본에 의한 검정 통계량을 직접 비교하여 일치하면 귀무가설이 기각되지만, 일치하지 않으면 귀무가설이 채택된다.  - 점 추정 방식에 의한 가설 검정은 귀무가설의 기각률이 낮다고 볼 수 있다 또한 검정 통계량과 모수의 참값 사이의 오차범위를 확인 할 수 없다.
- 구간 추정 방식으로 가설을 검정할 경우 오차범위에 의해서 결정된 하한값과 상한값의 신뢰구간과 검정 통계량을 비교하여 가설을 검정 – 추론 통계 분석에서는 구간 추정 방식을 더 많이 이용, 오차범위는 모표준편차가 알려지지 않은 경우 표본의 표준편차(S)를 이용하여 추정한다.



### 모평균의 구간 추정  

- 모집단으로부터 추출된 표본으로부터 모수와 관련된 통계량(statistics)들의 값을 계산하고, 이것을 이용하여 모집단의 특성(모수)을 알아내는 과정
- 모집단으로부터 추출한 표본으로부터 얻은 정보를 이용하여 모집단의 특성을 나타내는 값을 확률적으로 추측하는 추정(estimation)
- 유의수준과 표본의 검정 통계량을 비교하여 통계적 가설의 진위를 입증하는 가설 검정(hypotheses testing)



![1568853511090](assets/1568853511090.png)

![1568853520294](assets/1568853520294.png)

![1568853636135](assets/1568853636135.png)



```R
> N <- 10000
> X <- 165.1
> S <- 2
> low <- X-1.96 * S/sqrt(N) #신뢰구간의 하한값
> high <- X+1.96 * S/sqrt(N) #신뢰구간의 상한값
> low;high
[1] 165.0608
[1] 165.1392
> N <- 10000
> X <- 165.1
> S <- 2
> low <- X-1.96 * S/sqrt(N)   #신뢰구간의 하한값
> high <- X+1.96 * S/sqrt(N)   #신뢰구간의 상한값
> low;high
[1] 165.0608
[1] 165.1392
> # 신뢰구간으로 표본 오차
> # 하한값-평균신장 , 상한값-평균신장 값을 백분율로 적용
> (low-X)  * 100
[1] -3.92
> (high-X) * 100
[1] 3.92
# 신뢰구간의 표본 오차는 ±3.92

#해석 : 우리나라  중학교 2학년 남학생의 평균 신장이 95%신뢰수준에서 표본 오차는 ±3.92 범위에서 
#평균 165.1cm로 조사되었다면 실제 평균키는 165.0608 ~165.1392 사이에 나나탈 수 있다


```







### 표본오차

- 표본이 모집단의 특성과 정확히 일치하지 않아서 발생하는 확률의 차이
- 신뢰구간의 하한값에서 평균을 빼고, 상한값에서 평균을 뺀 값을 백분율로 적용

### 모 비율의 구간 추정

- 모비율(p) : 모집단에서 어떤 사건에 대한 비율  예) 제품의 불량율, 대선 후보 지지율 
- 모비율 추정 : 모집단으로부터 임의추출한 표본에서 어떤 사건에 대한 비율인 표본비율(𝑝 ̂)을 이용하여 모비율을 추정



![1568853779492](assets/1568853779492.png)





```R
##########표본의 비율로부터 모집단의 비율 구간 추정  ###################
#A반도체 회사의 사원을 대상으로 임의 추출한 150명을 조사한 결과 90명이 여자 사원이다
#표본 크기(n) : 150 
n <- 150
# 표본비율(????)  : 90/150 = 0.6
p <- 90/150
# 전체 여자 사원 비율 (모비율) 

> p-1.96 * sqrt(p*(1-p)/n)
[1] 0.5216
> p+1.96 * sqrt(p*(1-p)/n)
[1] 0.6784

#모집단의 비율 구간은 다음과 같습니다.  
0.5216 ≤ 모비율(P) ≤ 0.6784



```





### 단일 집단 검정

- 한 개의 집단과 기존 집단과의 비율 차이 검정은 기술 통계량으로 빈도수에 대한 비율에 의미가 있으며, 평균
  차이 검정은 표본 평균에 의미가 있다.



### 단일 집단 비율 검정   

- 단일 집단의 비율이 어떤 특정한 값과 같은지를 검정하는 방법
- 데이터 전처리 (이상치와 결측치 제거) -> 기술통계량(빈도분석) -> binom.test() -> 검정통계량 분석
- 비율 차이 검정 통계량을 바탕으로 귀무가설의 기각 여부를 결정한다



![1568856011898](assets/1568856011898.png)

![1568856016179](assets/1568856016179.png)





### 이항분포 비율 검정  

- 명목척도의 비율을 바탕으로 binom.test()를 이용하여 이항분포의 양측 검정을 통해서 검정 통계량을 구한 후 이를 이용하여 가설을 검정
- 이항분포는 이산변량이며, 그래프는 좌우대칭인 종 모양의 곡선 형태를 갖는다.



![1568856090605](assets/1568856090605.png)



- alternative=“two.sided”은 양측 검정을 의미
- conf.level=0.95는 95% 신뢰수준을 의미
- 귀무가설이 모평균=상수 일때와 모 평균 = 상수가 아닐때 양측가설 검정을 수행하고 방향성이 있는 경우 단측가설 검정을 수행
- alternative=“greater”은 방향성을 갖는 연구가설을 검정할 경우 이용된다.



### 양측검정

```R
> data <- read.csv(file.choose(), header = TRUE)
> head(data)
  no gender survey time
1  1      2      1  5.1
2  2      2      0  5.2
3  3      2      1  4.7
4  4      2      1  4.8
5  5      2      1  5.0
6  6      2      1  5.4
> str(data)
'data.frame':	150 obs. of  4 variables:
 $ no    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ gender: int  2 2 2 2 2 2 2 2 2 1 ...
 $ survey: int  1 0 1 1 1 1 1 1 0 1 ...
 $ time  : num  5.1 5.2 4.7 4.8 5 5.4 NA 5 4.4 4.9 ...

> #변수 : 번호, 성별, 만족도(명목척도), 시간

> x <- data$survey
> x
  [1] 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1
 [25] 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1
 [49] 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1
 [73] 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 [97] 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1
[121] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1
[145] 1 1 1 1 1 1
> summary(x)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0000  1.0000  1.0000  0.9067  1.0000  1.0000 
> length(x)
[1] 150
> table(x) #0:불만족, 1:만족
x
  0   1 
 14 136 


> library(prettyR)
> freq(x) #결측치 확인

Frequencies for x 
        1    0   NA
      136   14    0
%    90.7  9.3    0 
%!NA 90.7  9.3

> #만족도(명목척도)의 비율을 바탕으로 binom.test() 이항분포 양측검정 수행 -> 검정 통계량 -> 가설 검정
> binom.test(c(136,14), p=0.8)

	Exact binomial test

data:  c(136, 14)
number of successes = 136, number of trials =
150, p-value = 0.0006735
alternative hypothesis: true probability of success is not equal to 0.8
95 percent confidence interval:
 0.8483615 0.9480298
sample estimates:
probability of success 
             0.9066667 


> binom.test(c(136,14), p=0.8, alternative = "two.sided", conf.level = 0.95)

	Exact binomial test

data:  c(136, 14)
number of successes = 136, number of trials =
150, p-value = 0.0006735
alternative hypothesis: true probability of success is not equal to 0.8
95 percent confidence interval:
 0.8483615 0.9480298
sample estimates:
probability of success 
             0.9066667 

#해석 : p-value 유의확률 0.0006735로 유의수준 0.05보다 작기 때문에 기존 만족률(80%)과 차이가 있다


```



### 단측검정

```R
#방향성을 갖는 단측 검정 수행 (더 큰 비율인가? 검정)
> binom.test(c(136,14), p=0.8, alternative = "greater", conf.level = 0.95)

	Exact binomial test

data:  c(136, 14)
number of successes = 136, number of trials =
150, p-value = 0.0003179
alternative hypothesis: true probability of success is greater than 0.8
95 percent confidence interval:
 0.8579426 1.0000000
sample estimates:
probability of success 
             0.9066667 

#해석 : p-value 유의확률 0.0003179로 유의수준 0.05보다 작기 때문에 기존 만족률 80%  이상의 효과를 얻을 수 있다 
 #CS 교육후에 고객의 불만율은 낮아졌다고 할 수 있습니다. 귀무가설은 기각이고 연구가설이 채택되므로 CS교육에 효과가 있다.

> #불만율 기준 비율 검정
> #불만율 기준 비율 검정
> binom.test(c(14, 136), p=0.2)

	Exact binomial test

data:  c(14, 136)
number of successes = 14, number of trials =
150, p-value = 0.0006735
alternative hypothesis: true probability of success is not equal to 0.2
95 percent confidence interval:
 0.05197017 0.15163853
sample estimates:
probability of success 
            0.09333333 

> binom.test(c(14, 136), p=0.2,  alternative="less", conf.level=0.95)

	Exact binomial test

data:  c(14, 136)
number of successes = 14, number of trials =
150, p-value = 0.0003179
alternative hypothesis: true probability of success is less than 0.2
95 percent confidence interval:
 0.0000000 0.1420574
sample estimates:
probability of success 
            0.09333333 

> binom.test(c(14, 136), p=0.2,  alternative="less", conf.level=0.95)

	Exact binomial test

data:  c(14, 136)
number of successes = 14, number of trials =
150, p-value = 0.0003179
alternative hypothesis: true probability of success is less than 0.2
95 percent confidence interval:
 0.0000000 0.1420574
sample estimates:
probability of success 
            0.09333333 



```





### 단일집단  평균 검정  



- 단일집단의 평균이 어떤 특정한 집단의 평균과 차이가 있는지를 검정하는 방법

- 데이터 전처리 (이상치와 결측치 제거) -> 기술통계량(평균) -> 정규분포( shapiro.test()) -> t.test() 또는 wilcox.test()  -> 검정통계량 분석

- 모수 검정인 경우 T검정을 수행

- 비모수 검정인 경우 Wilcox 검정을 수행



![1568857635906](assets/1568857635906.png)

![1568857640631](assets/1568857640631.png)



#### 단일표본 t-test

```R
> head(data)
  no gender survey time
1  1      2      1  5.1
2  2      2      0  5.2
3  3      2      1  4.7
4  4      2      1  4.8
5  5      2      1  5.0
6  6      2      1  5.4
> str(data)
'data.frame':	150 obs. of  4 variables:
 $ no    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ gender: int  2 2 2 2 2 2 2 2 2 1 ...
 $ survey: int  1 0 1 1 1 1 1 1 0 1 ...
 $ time  : num  5.1 5.2 4.7 4.8 5 5.4 NA 5 4.4 4.9 ...
> x <- data$time
> summary(x)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  3.000   5.000   5.500   5.557   6.200   7.900 
   NA's 
     41 
> length(x)
[1] 150
> mean(x, na.rm = T)
[1] 5.556881
> x1 <- na.omit(x)
> mean(x1)
[1] 5.556881


hist(x1)  
#stats패키지에서 정규성 검정 - qqnorm(), qqline()는 정규분포 시각화
install.packages("stats")
library(stats)
qqnorm(x1)
qqline(x1, lty=1, col='blue')
```

![1568858455955](assets/1568858455955.png)

![1568858470869](assets/1568858470869.png)



```R
> # 모수 검정 :T-검정 
> t.test(x1, mu=5.2)  #x1객체와 기존 모집단의 평균 5.2시간 비교

	One Sample t-test

data:  x1
t = 3.9461, df = 108, p-value = 0.0001417
alternative hypothesis: true mean is not equal to 5.2
95 percent confidence interval:
 5.377613 5.736148
sample estimates:
mean of x 
 5.556881 

> t.test(x1, mu=5.2, alter="two.side", conf.level=0.95)

	One Sample t-test

data:  x1
t = 3.9461, df = 108, p-value = 0.0001417
alternative hypothesis: true mean is not equal to 5.2
95 percent confidence interval:
 5.377613 5.736148
sample estimates:
mean of x 
 5.556881 

#해석 : 검정 통계량 p-value 값은 0.0001417 로 유의수준 0.05보다 작기 때문에
#국내에서 생산된 노트북과 A회사에서 생산된 노트북의 평균 사용시간에 차이가 있다
#x1의 평균은 5.55688(점추정)는 신뢰구간에 포함되고
#A회사에서 생산된 노트북의 평균 사용시간 5.2는 신뢰구간을 벗어나므로 귀무가설이 기각된다

> #방향성을 갖는 단측 검정
> t.test(x1, mu=5.2, alter="greater", conf.level=0.95)

	One Sample t-test

data:  x1
t = 3.9461, df = 108, p-value = 7.083e-05
alternative hypothesis: true mean is greater than 5.2
95 percent confidence interval:
 5.406833      Inf
sample estimates:
mean of x 
 5.556881 

#연구가설 : '국내에서 생산된 노트북 평균 사용시간이  A회사에서 생산된 노트북의 평균 사용시간보다 더 길다'
#해석 : 검정 통계량 p-value 값은 7.083e-6로 유의수준 0.05보다 매우 작기 때문에 
#귀무가설 :'A회사에서 생산된 노트북의 평균 사용시간이 국내에서 생산된 노트북 평균 사용시간보다 더 길다'고 할 수 있다.


> qt(7.083e-6, 108) 
[1] -4.549031
> #귀무가설 임계값 계산 qt(p-value, df)
> #귀무가설을 기각할 수 있는 임계값  
> qt(7.083e-6, 108) 
[1] -4.549031
> 
> #계산 결과


> #두 집단의 비율 차이 검정
> #prop.test ('pt교육 만족도와 코딩교육 만족도', '교육방법에 대한 변량-시행횟수')
> prop.test(c(110, 135), c(150, 150))

	2-sample test for equality of proportions with
	continuity correction

data:  c(110, 135) out of c(150, 150)
X-squared = 12.824, df = 1, p-value = 0.0003422
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.25884941 -0.07448392
sample estimates:
   prop 1    prop 2 
0.7333333 0.9000000 

> prop.test(c(110, 135), c(150, 150), alter="two.sided", conf.level=0.95)

	2-sample test for equality of proportions with
	continuity correction

data:  c(110, 135) out of c(150, 150)
X-squared = 12.824, df = 1, p-value = 0.0003422
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.25884941 -0.07448392
sample estimates:
   prop 1    prop 2 
0.7333333 0.9000000 


#해석 : 검정 통계량 p-value 값은 0.0003422로 유의수준 0.05보다 작기 때문에 두 교육방법 간의 만족도에 차이가 있다 (연구가설 채택)
#검정 통계량 X-squared로 가설 검정을 수행하면 df 1일때 기각역은 3.84이고 X-squared 12.82..가 더 크기 때문에 귀무가설을 기각할 수 있다



```



### 두 집단 평균 검정(독립표본 T검정)



```R
> #기술통계량(평균)
> length(ascore)
[1] 227
> a <- subset(result, method == 1)
> b <- subset(result, method == 2)
> ascore <- a$score
> bscore <- b$score
> #기술통계량(평균)
> length(ascore)
[1] 109
> length(bscore)
[1] 118

> mean(ascore)
[1] 5.556881
> mean(bscore)
[1] 5.80339
> #분산의 동질성 검정
> var.test(ascore, bscore)

	F test to compare two variances

data:  ascore and bscore
F = 1.2158, num df = 108, denom df = 117,
p-value = 0.3002
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.8394729 1.7656728
sample estimates:
ratio of variances 
          1.215768 


#해석 : 검정 통계량 p-value 값은 0.3002 로 유의수준 0.05보다 크기 때문에 
#두 집단 간의 분포 형태가 동일하다고 볼 수 있다.


> t.test(ascore, bscore)

	Welch Two Sample t-test

data:  ascore and bscore
t = -2.0547, df = 218.19, p-value = 0.0411
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.48296687 -0.01005133
sample estimates:
mean of x mean of y 
 5.556881  5.803390 

> # 두 집단 평균 차이 검정
> t.test(ascore, bscore)

	Welch Two Sample t-test

data:  ascore and bscore
t = -2.0547, df = 218.19, p-value = 0.0411
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.48296687 -0.01005133
sample estimates:
mean of x mean of y 
 5.556881  5.803390 

> t.test(ascore, bscore, alter="two.sided", conf.int=TRUE, conf.level=0.95)

	Welch Two Sample t-test

data:  ascore and bscore
t = -2.0547, df = 218.19, p-value = 0.0411
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.48296687 -0.01005133
sample estimates:
mean of x mean of y 
 5.556881  5.803390 

#해석 : 검정 통계량 p-value 값은 0.0411로 유의수준 0.05보다 작기 때문에
#두 집단간의 평균에 차이가 있다

> #단측 가설 검정 (ascore가 기준으로 비교 -> ascore보다 bscore가 더 큰지 여부)
> t.test(ascore, bscore, alter="greater", conf.int=TRUE, conf.level=0.95)

	Welch Two Sample t-test

data:  ascore and bscore
t = -2.0547, df = 218.19, p-value = 0.9794
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 -0.4446915        Inf
sample estimates:
mean of x mean of y 
 5.556881  5.803390 

#해석 : 검정 통계량 p-value 값은 0.9794로 유의수준 0.05보다 크기 때문에
#pt교육보다 코딩교육의 실기 점수 평균이 더 크다



> t.test(ascore, bscore, alter="less", conf.int=TRUE, conf.level=0.95)

	Welch Two Sample t-test

data:  ascore and bscore
t = -2.0547, df = 218.19, p-value = 0.02055
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
        -Inf -0.04832672
sample estimates:
mean of x mean of y 
 5.556881  5.803390 

#해석 : 검정 통계량 p-value 값은 0.02055로 유의수준 0.05보다 작기 때문에
#pt교육이 코딩교육의 실기 점수 평균이 더 낮다

```





### 대응 두 집단 평균 검정(대응 표본 T검정)



```R
> data <- read.csv("./data4/paired_sample.csv", header=TRUE)
> head(data)
  no before after
1  1    5.1   6.3
2  2    5.2   6.3
3  3    4.7   6.5
4  4    4.8   5.9
5  5    5.0   6.5
6  6    5.4   7.3
> str(data)  
'data.frame':	100 obs. of  3 variables:
 $ no    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ before: num  5.1 5.2 4.7 4.8 5 5.4 5 5 4.4 4.9 ...
 $ after : num  6.3 6.3 6.5 5.9 6.5 7.3 5.9 6.2 6 7.2 ...


data <- read.csv("./data4/paired_sample.csv", header=TRUE)
head(data)
str(data)  

result <- subset(data, !is.na(after), c(before, after))

> length(result$before)  #결측치 4개 제외됨
[1] 96
> length(result$after)
[1] 96


> x <- result$before
> y <- result$after
> mean(x)
[1] 5.16875
> mean(y)
[1] 6.220833


> var.test(x, y, paired = TRUE)

	F test to compare two variances

data:  x and y
F = 1.0718, num df = 95, denom df = 95, p-value
= 0.7361
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.7151477 1.6062992
sample estimates:
ratio of variances 
          1.071793 

> #평균 차이 검정
> t.test(x, y, paired=TRUE, alter="two.sided", conf.int=TRUE, conf.level=0.95)

	Paired t-test

data:  x and y
t = -13.642, df = 95, p-value < 2.2e-16
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -1.205184 -0.898983
sample estimates:
mean of the differences 
              -1.052083 

#해석 : 검정 통계량 p-value 값은  2.2e-16 로 유의수준 0.05보다 매우 작기 때문에
#두 집단간의 평균에 차이가 있다 

> t.test(x, y, paired=TRUE, alter="less", conf.int=TRUE, conf.level=0.95)

	Paired t-test

data:  x and y
t = -13.642, df = 95, p-value < 2.2e-16
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
       -Inf -0.9239849
sample estimates:
mean of the differences 
              -1.052083 

#해석 : 검정 통계량 p-value 값은 2.2e-16 로 유의수준 0.05보다 매우 작기 때문에
#x 집단 평균이 y집단의 평균보다 작다고 할 수 있다


```







### 세집단 검정 

- 비율 차이 검정은 기술 통계량으로 빈도수에 대한 비율에 의미가 있으며, 세 집단의 평균 차이 검정은 분산 분석이라고 한다.



### 세집단 비율검정

- 데이터 전처리 -> 세 집단  subset 작성 -> prop.test()  -> 검정통계량 분석



![1568868113044](assets/1568868113044.png)



```R
> data <- read.csv("./data4/three_sample.csv", header=TRUE)
> head(data)
  no method survey score
1  1      1      1   3.2
2  2      2      0    NA
3  3      3      1   4.7
4  4      1      0    NA
5  5      2      1   7.8
6  6      3      1   5.4
> str(data)
'data.frame':	150 obs. of  4 variables:
 $ no    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ method: int  1 2 3 1 2 3 1 2 3 1 ...
 $ survey: int  1 0 1 0 1 1 0 0 1 0 ...
 $ score : num  3.2 NA 4.7 NA 7.8 5.4 NA 8.4 4.4 2.8 ...


> method <- data$method
> survey <- data$survey
> table(method, useNA = "ifany")
method
 1  2  3 
50 50 50 
> table(method, survey, useNA = "ifany") #교차분할표
      survey
method  0  1
     1 16 34
     2 13 37
     3 11 39
> #prop.test((교육방법에 대한 만족 빈도수), (변량의 길이))
> prop.test(c(34,37,39), c(50,50,50))

	3-sample test for equality of proportions
	without continuity correction

data:  c(34, 37, 39) out of c(50, 50, 50)
X-squared = 1.2955, df = 2, p-value = 0.5232
alternative hypothesis: two.sided
sample estimates:
prop 1 prop 2 prop 3 
  0.68   0.74   0.78 


#해석 : 검정 통계량 p-value 값은  0.5232로 유의수준 0.05보다
#세 교육방법 간의 만족도에 차이가 없다 (귀무가설 채택)

#X-squared 검정 통계량 1.2955는 df 2의 기각값은 5.991보다 작기 때문에 귀무가설을 기각할 수 없다


```





### 분산분석 (F 검정)



- 분산분석(ANOVA  Analysis)-  T 검정과 동일하게 평균에 의한 차이 검정 방법
- 두 집단 이상의 평균 차이를 검정
  - 예) 의학연구 분야에서 개발된 3가지 치료제가 있다고 가정할 때, 이 3가지 치료제의 효과에 차이가 있는지를 검정
- 분산분석은 가설 검정을 위해 F 분포를 따른 F 통계량을  검정 통계량으로 사용하기 때문에 F검정이라고 한다.
-  데이터 전처리 -> 각 집단 subset 작성 -> 기술 통계량(평균)  ->  동질성분포 (barlett.test()) -> aov() 또는 kruskal.test() -> TukeyHSD()

- 분석에서 집단 간의 동질성 여부를 검정하기 위해서는 bartlett.test()를 이용

- 집단 간의 분포가 동질한 경우 분산분석을 수행하는  aov() 함수를 이용

- 비모수 검정 방법인 kruskal.test() 를 이용하여 분석을 수행하고, 

- 마지막으로 TukeyHSD() 함수를 이용하여 사후 검정을 수행한다

![1568869719673](assets/1568869719673.png)







##### 세 집단의 평균 차이 분석

````R
> data <- read.csv("./data4/three_sample.csv", header=TRUE)
> head(data)
  no method survey score
1  1      1      1   3.2
2  2      2      0    NA
3  3      3      1   4.7
4  4      1      0    NA
5  5      2      1   7.8
6  6      3      1   5.4
> str(data) #method, score
'data.frame':	150 obs. of  4 variables:
 $ no    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ method: int  1 2 3 1 2 3 1 2 3 1 ...
 $ survey: int  1 0 1 0 1 1 0 0 1 0 ...
 $ score : num  3.2 NA 4.7 NA 7.8 5.4 NA 8.4 4.4 2.8 ...

> data <- subset(data, !is.na(score), c(method, score))  #결측치 제거
> head(data)
  method score
1      1   3.2
3      3   4.7
5      2   7.8
6      3   5.4
8      2   8.4
9      3   4.4


> plot(data$score) #산점도

````

![1568870187500](assets/1568870187500.png)



```R
> barplot(data$score)
```

![1568870237295](assets/1568870237295.png)



```R
> mean(data$score)
[1] 14.44725

> length(data$score) #이상치 제거 전 데이터 개수 : 91
[1] 91

> data2 <- subset(data, score<=14)
> length(data2$score)   # 이상치 제거 개수 :88
[1] 88


> x <- data2$score
> boxplot(x)

```

![1568870410947](assets/1568870410947.png)

##### 

```R
#교육방법에 따른 세 집단의 subset 생성

> data2$method2[data2$method==1] <- "방법1"
> data2$method2[data2$method==2] <- "방법2"
> data2$method2[data2$method==3] <- "방법3"

#교육방법에 따른 빈도수
> mCnt <- table(data2$method2)
> mAvg <- tapply(data2$score, data2$method2, mean)

> df <- data.frame(교육방법 = mCnt, 성적 = mAvg)
> df
      교육방법.Var1 교육방법.Freq     성적
방법1         방법1            31 4.187097
방법2         방법2            27 6.800000
방법3         방법3            30 5.610000


> #세 집단의 동질성 검정
> #bartlett.test(종속변수 ~ 독립변수, data = 데이터셋)
> bartlett.test(score ~ method, data = data2)

	Bartlett test of homogeneity of variances

data:  score by method
Bartlett's K-squared = 3.3157, df = 2, p-value
= 0.1905


#해석 : 검정 통계량 p-value 값은 0.1905 로 유의수준 0.05보다 크기 때문에 세 집단 간으 분포 형태가 동질하다고 볼 수 있다.

#세 집단의 평균 차이 검정 : aov()
help(aov) #aov(종속변수 ~ 독립변수, data = 데이터 셋)
> result <- aov(score ~ method2, data = data2)
> names(result)
 [1] "coefficients"  "residuals"     "effects"      
 [4] "rank"          "fitted.values" "assign"       
 [7] "qr"            "df.residual"   "contrasts"    
[10] "xlevels"       "call"          "terms"        
[13] "model"        
> summary(result)
            Df Sum Sq Mean Sq F value   Pr(>F)    
method2      2  99.37   49.68   43.58 9.39e-14 ***
Residuals   85  96.90    1.14                     
---
Signif. codes:  
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#해석 : 검정 통계량 p-value 값은 9.39e-14 로 유의수준 0.05보다 매우 작기 때문에
#교육방법에 따른 세 집단 간의 실기시험 평균에 차이가 있다 (연구가설 채택)

#F 검정 통계량 43.58은  -1.96 ~ +1.96 범위의 귀무가설의 채택역에 해당하지 않으므로
#귀무가설을 기각할 수 있다 (귀무가설을 기각하고 연구가설 채택)


#집단간의 평균의 차에 대한 비교 => 사후 검정 수행
 
> TukeyHSD(result)  #분산분석 결과로 사후 검정
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = score ~ method2, data = data2)

$method2
                 diff        lwr        upr     p adj
방법2-방법1  2.612903  1.9424342  3.2833723 0.0000000
방법3-방법1  1.422903  0.7705979  2.0752085 0.0000040
방법3-방법2 -1.190000 -1.8656509 -0.5143491 0.0001911


> #diff 폭(평균의 차이)의 크기
#lwr, upr은 신뢰구간의 하한값과 상한값
> plot(TukeyHSD(result))

```

![1568871664047](assets/1568871664047.png)



```R
#결론 :교육방법에 따른 세 집단 간의 실기시험 평균에 차이가 있으며 세 교육방법에 따른 분석 결과 방법2와 방법1의 차이가 가장 높다
```







### 연습문제

#### 연습문제01>

```R
연습문제01>
중소기업에서 생산한 HDTV 판매율을 높이기 위해서 프로모션을 진행한 결과 기존 구
매비율 보다 15% 향상되었는지를 각 단계별로 분석을 수행하여 검정하시오.
연구가설(H1) : 기존 구매비율과 차이가 있다.
귀무가설(H0) : 기존 구매비율과 차이가 없다.
조건) 구매여부 변수 : buy (1: 구매하지 않음, 2: 구매)
hdtv <- read.csv("hdtv.csv", header=TRUE)


> binom.test(c(40,10), p=0.15)

	Exact binomial test

data:  c(40, 10)
number of successes = 40, number of trials =
50, p-value < 2.2e-16
alternative hypothesis: true probability of success is not equal to 0.15
95 percent confidence interval:
 0.6628169 0.8996978
sample estimates:
probability of success 
                   0.8 



#해설> 귀무가설 채택 : 기존 구매비율(15%)과 차이가 없다.




> #  방향성이 있는 단측가설 검정
> binom.test(c(10,40), p=0.15, alternative="greater", conf.level=0.95)

	Exact binomial test

data:  c(10, 40)
number of successes = 10, number of trials =
50, p-value = 0.2089
alternative hypothesis: true probability of success is greater than 0.15
95 percent confidence interval:
 0.1127216 1.0000000
sample estimates:
probability of success 
                   0.2 

> #p-value=0.2089
> binom.test(c(10,40), p=0.15, alternative="less", conf.level=0.95) #p-value =0.8801

	Exact binomial test

data:  c(10, 40)
number of successes = 10, number of trials =
50, p-value = 0.8801
alternative hypothesis: true probability of success is less than 0.15
95 percent confidence interval:
 0.0000000 0.3155961
sample estimates:
probability of success 
                   0.2 
#해설> 방향성이 잇는 단측가설은 모두 기각된다.




> binom.test(c(10,40), p=0.11, alternative="greater", conf.level=0.95)

	Exact binomial test

data:  c(10, 40)
number of successes = 10, number of trials =
50, p-value = 0.04345
alternative hypothesis: true probability of success is greater than 0.11
95 percent confidence interval:
 0.1127216 1.0000000
sample estimates:
probability of success 
                   0.2 



#해설> 구매비율은 11%을 넘지 못한다.

```



#### 연습문제02>

```R

우리나라 전체 중학교 2학년 여학생 평균 키가 148.5cm로 알려져 있는 상태에서 A중
학교 2학년 전체 500명을 대상으로 10%인 50명을 표본으로 선정하여 표본평균신장을
계산하고 모집단의 평균과 차이가 있는지를 각 단계별로 분석을 수행하여 검정하시오.
단계1: 데이터셋 가져오기 
read.csv("student_height.csv", header=TRUE)
기술 통계량 평균 계산
정규성 검정
가설 검정


> stheight<- read.csv("./data4/student_height.csv", header=TRUE)
> stheight
   sudent.id height
1          1    148
2          2    150
3          3    149
4          4    144
5          5    152
6          6    150
7          7    155
8          8    147
9          9    148
10        10    151
11        11    150
12        12    149
13        13    150
14        14    144
15        15    147
16        16    150
17        17    153
18        18    147
19        19    152
20        20    150
21        21    151
22        22    149
23        23    149
24        24    153
25        25    147
26        26    152
27        27    160
28        28    165
29        29    140
30        30    141
31        31    148
32        32    151
33        33    150
34        34    149
35        35    150
36        36    144
37        37    147
38        38    150
39        39    153
40        40    147
41        41    152
42        42    148
43        43    151
44        44    150
45        45    149
46        46    150
47        47    144
48        48    147
49        49    150
50        50    147
> height <- stheight$height
> head(height)
[1] 148 150 149 144 152 150
> # 단계2: 기술 통계량/결측치 확인
> length(height) #50
[1] 50
> summary(height) # 149.4
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  140.0   147.0   150.0   149.4   151.0   165.0 
> x1 # 정제 데이터
  [1] 5.1 5.2 4.7 4.8 5.0 5.4 5.0 4.4 4.9 5.2 4.3 5.8
 [13] 5.7 5.1 5.3 5.4 5.1 4.8 4.1 4.8 5.0 5.2 4.7 4.4
 [25] 5.2 5.3 4.0 6.1 6.3 4.1 5.0 5.3 4.0 5.1 3.8 5.6
 [37] 5.3 7.0 6.4 5.5 4.7 3.9 4.1 5.0 6.0 3.3 5.6 5.6
 [49] 6.2 5.9 3.4 6.3 6.4 3.0 6.8 5.2 5.5 5.8 5.4 6.0
 [61] 6.7 5.2 5.6 5.5 6.1 5.0 5.7 5.7 5.1 5.7 6.3 7.1
 [73] 6.5 4.9 6.2 7.2 6.5 6.4 6.8 5.8 6.7 7.7 6.9 7.7
 [85] 6.7 6.2 6.1 6.4 5.8 5.2 7.9 6.4 6.3 6.1 5.3 6.3
 [97] 4.8 6.0 6.9 6.1 4.3 4.9 5.5 6.7 5.4 5.3 6.5 6.2
[109] 5.9
attr(,"na.action")
 [1]   7  11  13  17  20  26  28  31  35  38  42  47
[13]  50  53  55  57  59  62  66  68  70  74  78  79
[25]  82  84  90  93  95  98 102 104 106 109 114 116
[37] 117 120 122 124 126
attr(,"class")
[1] "omit"
> mean(x1) # 149.4 : 평균신장
[1] 5.556881
> 단계3: 정규성 검정
Error: unexpected symbol in "단계3: 정규성 검정"
> shapiro.test(x1) # p-value = 0.0001853 -> 정규분포 아님

	Shapiro-Wilk normality test

data:  x1
W = 0.99137, p-value = 0.7242

> #단계4: 가설검정 - 양측검정
> wilcox.test(x1, mu=148.5) # p-value = 0.067

	Wilcoxon signed rank test with continuity
	correction

data:  x1
V = 0, p-value < 2.2e-16
alternative hypothesis: true location is not equal to 148.5

> wilcox.test(x1, mu=148.5, alter="two.side", conf.level=0.95) # p-value = 0.067

	Wilcoxon signed rank test with continuity
	correction

data:  x1
V = 0, p-value < 2.2e-16
alternative hypothesis: true location is not equal to 148.5

> 
> #해설> 귀무가설을 기각할 수 없다.



```



#### 연습문제03>

```R

대학에 진학한 남학생과 여학생을 대상으로 진학한 대학에 대해서 만족도에 차이가 있
는가를 검정하시오. 
조건1) 파일명 : two_sample.csv
조건2, 변수명 : gender(1,2), survey(0,1)


gender <- data$gender
survey <- data$survey
> table(gender, useNA = "ifany")
gender
  1   2 
174 126 
> table(gender, survey, useNA = "ifany")
      survey
gender   0   1
     1  36 138
     2  19 107
> prop.test(c(138, 107), c(174,126))

	2-sample test for equality of proportions with
	continuity correction

data:  c(138, 107) out of c(174, 126)
X-squared = 1.1845, df = 1, p-value = 0.2765
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.14970179  0.03749599
sample estimates:
   prop 1    prop 2 
0.7931034 0.8492063 


# p-value = 0.2765 은 0.05보다 크므로 만족도에 대한 차이는 없다.

```





```R

연습문제04>
교육방법에 따라 시험성적에 차이가 있는지 검정하시오. 
조건1) 파일 : twomethod.csv
조건2) 변수 : method(교육방법), score(시험성적)
조건3) 모델 : 교육방법(명목) -> 시험성적(비율)
조건4) 전처리 : 결측치 제거 


x <- result$method
a <- subset(result, method == 1)
b <- subset(result, method == 2)
ascore <- a$score
bscore <- b$score
var.test(ascore, bscore)
t.test(ascore, bscore)

> t.test(ascore, bscore)

	Welch Two Sample t-test

data:  ascore and bscore
t = -5.6056, df = 43.705, p-value = 1.303e-06
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -17.429294  -8.209667
sample estimates:
mean of x mean of y 
 16.40909  29.22857 




#해석 : 검정 통계량 p-value 값은 1.303e-06로 유의수준 0.05보다 작기 떄문에
#교육방법간의 차이가 있다.


> t.test(b, a, alter="greater", conf.int=TRUE, conf.level=0.95) #

	Welch Two Sample t-test

data:  b and a
t = 2.9879, df = 111.72, p-value = 0.001727
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 3.074088      Inf
sample estimates:
mean of x mean of y 
15.614286  8.704545 

```





## 요인분석

- 변수들의 상관성을 바탕으로 변수를 정제하여 상관관계 분석이나회귀분석에 설명변수(독립변수)로 사용된다.  
- 다수의 변수를 대상으로 변수간의 관계를 분석하여 공통차원으로 축약하는 통계기법
- 데이터를 축소하는 변수의 정제 과정
- 여러 가지 항목들을 비슷한 항목으로 묶는 것으로 여러 변수 사이에 존재하는 상호관계를 분석하여 타당성을 검정하고, 공통으로 속해있는 차원이나 요인들을 밝혀냄으로써 변수를 축소하는 과정
- 탐색적 요인분석 – 요인분석을 할 때 사전에 어던 변수끼리 묶어야 한다는 전제를 두지 않고 분석하는 방법
- 확인적 요인 분석 – 사전에 묶일 것으로 기대되는 항목끼리 묶여 지는지를 조사하는 방법  

#### 타당성 

- 측정 도구가 측정하고자 하는 것을 정확히 측정할 수 있는 정도를 의미

- 통계량 검정 이전에 구성 타당성(Construct validity)  검증을 위해서 요인분석을 실시한다



#### 요인 분석 전제조건 

- 하위요인으로 구성되는 데이터 셋이 준비되어 있어야 한다

- 분석에 사용되는 변수는 등간척도나 비율척도이어야 하며, 표본의 크기는 최소 50개 이상이 바람직하다

- 요인분석은 상관관계가 높은 변수들까리 그룹화하는 것이므로 변수 간의 상관관계가 매우 낮다면 (보통 ±3 이하) 그  자료는 요인분석에 적합하지 않다



#### 요인 분석 (Factor Analysis) 목적

- 자료의 요약 : 변인을 몇 개의 공통된 변인으로 묶음

- 변인 구조 파악 : 변인들의 상호관계 파악(독립성등)

- 불필요한 변인 제거 : 중요도가 떨어진 변수 제거

- 측정 도구 타당성 검증 : 변인들이 동일한 요인으로 묶이는지 확인  



#### 요인 분석에 대한 활용 방안 

- 측정 도구가 정확히 측정했는지를 알아보기 위해서 측정 변수들이 동일한 요인으로 묶이는지를 검정한다(타당성 검정)

- 변수들의 상관관계가 높은 것끼리 묶어서 변수를 정제한다. (변수 축소)

- 변수의 중요도를 나타내는 요인적재량이 0.4 미만이면 설명력이 부족한 요인으로 판단하여 제거한다 (변수 제거)

- 요인분석에서 얻어지는 결과를 이용하여 상관분석이나 회귀분석의 설명변수로 활용한다.





#### 공통요인으로 변수 정제

- 특정 항목으로 묶여 지는데 사용되는 요인수 결정은 주성분 분석방법과 상관계수 행렬을 이용한 초기 고유값을 이용한다.

- 단계1] 주성분 분석 - 변동량(분산)에 영향을 주는 주요 성분을 분석하는 방법으로 요인분석에서 사용될 요인의 개수를 결정하는데 주로 이용된다.
- 단계2] •고유값으로 요인수 분석 – 고유값이란 어떤 행렬로부터 유도되는 실수값을 의미한다. 일반적으로 변화량의 (총분산)을 기준으로 요인수를 결정하는데 이용된다.
  상관계수 행렬을 대상으로 초기 고유값 요인수 분석 eigen()은 상관계수 행렬을 대상으로 초기 고유값과 고유벡터를 계산하는 함수이다.



#### 변수간의 상관관계 분석과 요인분석

- 단계1] 상관관계 분석 – 변수 간의 상관성으로 공통요인 추출

- 단계2] 요인 회전법 적용 – 요인 해석이 어려운 경우 어느 한 요인을 높게 나타내기 위해서 요인축을 회전하는 방법이 있다 베리멕스 회전법을 기본으로 사용한다.

![1568882217526](assets/1568882217526.png)

- 요인분석결과에서만약 p-value 값이 0.05 미만이면 요인수가 부족하다는 의미로 요인수를 늘려서 다시 분석을 수행해야 한다.

- Uniqueness항목은 유효성을 판단하여 제시한 값으로 통상 0.05이하이면 유효한 것으로 본다
- Loading 항목은 요인 적재값(Loadings)를 보여주는 항목으로 각 변수와 해당 요인 간의 상관관계계수를 제시한다.

- 요인 적재값(요인 부하량)이 통상 +0.4 이상이면 유의하다고 볼 수 있다. +0.4 미만이면 설명력이 부족한 요인(중요도가 낮은 변수)으로 판단할 수 있다

- SS loadings 항목은
각 요인 적재값의 제곱의 합을 제시한 값으로 각 요인의 설명력을 보여준다.
- Proportion
Var 항목은
설명된 요인의 분산 비율로 각 요인이 차지하는 설명력의 비율이다.
- Cumulative Var 항목은
누적 분산 비율로 요인의 분산 비율을 누적하여 제시한 값으로 정보손실이 너무 크면 요인분석의 의미가 없어진다.





#### 공통요인으로 변수를 정제하는 요인분석

```R
> # 6개 과목 (s1~s6) 
> # 점수벡터 (5점 만점, 척도:5)
> s1 <- c(1, 2, 1, 2, 3, 4, 2, 3, 4, 5)  #자연과학
> s2 <- c(1, 3, 1, 2, 3, 4, 2, 4, 3, 4)  # 물리화학
> s3 <- c(2, 3, 2, 3, 2, 3, 5, 3, 4, 2)  #인문사회
> s4 <- c(2, 4, 2, 3, 2, 3, 5, 3, 4, 1)  # 신문방송
> s5 <- c(4, 5, 4, 5, 2, 1, 5, 2, 4, 3)  #응용수학
> s6 <- c(4, 3, 4, 4, 2, 1, 5, 2, 4, 2)  # 추론통계
> name <-1:10  #각 과목의 문제 이름


> subject <- data.frame(s1, s2, s3, s4, s5, s6)
> str(subject)
'data.frame':	10 obs. of  6 variables:
 $ s1: num  1 2 1 2 3 4 2 3 4 5
 $ s2: num  1 3 1 2 3 4 2 4 3 4
 $ s3: num  2 3 2 3 2 3 5 3 4 2
 $ s4: num  2 4 2 3 2 3 5 3 4 1
 $ s5: num  4 5 4 5 2 1 5 2 4 3
 $ s6: num  4 3 4 4 2 1 5 2 4 2


> #데이터 프레임 생성
> subject <- data.frame(s1, s2, s3, s4, s5, s6)
> str(subject)
'data.frame':	10 obs. of  6 variables:
 $ s1: num  1 2 1 2 3 4 2 3 4 5
 $ s2: num  1 3 1 2 3 4 2 4 3 4
 $ s3: num  2 3 2 3 2 3 5 3 4 2
 $ s4: num  2 4 2 3 2 3 5 3 4 1
 $ s5: num  4 5 4 5 2 1 5 2 4 3
 $ s6: num  4 3 4 4 2 1 5 2 4 2
> pc <- prcomp(subject) # scale = TRUE
> summary(pc)
Importance of components:
                         PC1    PC2     PC3     PC4
Standard deviation     2.389 1.5532 0.87727 0.56907
Proportion of Variance 0.616 0.2603 0.08305 0.03495
Cumulative Proportion  0.616 0.8763 0.95936 0.99431
                           PC5     PC6
Standard deviation     0.19315 0.12434
Proportion of Variance 0.00403 0.00167
Cumulative Proportion  0.99833 1.00000
> plot(pc)

```

![1568881657605](assets/1568881657605.png)



#### 고유값으로 요인 수 분석



```R
> # 고유값으로 요인 수 분석 
> en <- eigen(cor(subject)) # $values : 고유값, $vectors : 고유벡터  
> names(en) # "values"  "vectors"
[1] "values"  "vectors"
> en$values
[1] 3.44393944 1.88761725 0.43123968 0.19932073
[5] 0.02624961 0.01163331
> en$vectors
           [,1]         [,2]        [,3]       [,4]
[1,] -0.4062499 -0.351093036  0.63460534  0.3149622
[2,] -0.4319311 -0.400526644  0.11564711 -0.4422216
[3,]  0.2542077 -0.628807884 -0.06984072  0.3339036
[4,]  0.3017115 -0.566028650 -0.37734321 -0.2468016
[5,]  0.4763815  0.008436692  0.58035475 -0.6016209
[6,]  0.5155637  0.021286661  0.31595023  0.4133867
            [,5]        [,6]
[1,]  0.45699508  0.03041553
[2,] -0.57042232  0.34452594
[3,] -0.35389906 -0.54622817
[4,]  0.50326085  0.36333366
[5,]  0.05643527 -0.26654314
[6,] -0.28995329  0.61559319
> en$values # $values : 고유값(스칼라) 보기 
[1] 3.44393944 1.88761725 0.43123968 0.19932073
[5] 0.02624961 0.01163331
> plot(en$values, type="o") # 고유값을 이용한 시각화 

```

![1568881846262](assets/1568881846262.png)





#### 베리맥스 요인회전법

- 요인분석을 실시하면 요인행렬이 구해지는데, 이 행렬은 어떤 변수들이 어떤 요인에 의해 높게 관계 되어 있는지를 보여주지 않는다.

- 따라서 요인축의 회전을 통해서 특정 변수가 어떤 요인과 관계가 있는지를 나타내주어야 한다.

- 요인회전법은 직각회전과 사각회전 방식이 있다.

- 직각회전 방식인 베리멕스(varimax)는 요인행렬의 열(Column)에 위치한 변수들의 분산 합계가 최대화되도록 요인 적재량 +1, -1, 0에 가깝도록 해주는 회전법으로 각 요인 간의 상관관계가 없다고 자정한 경우 사용되는 방법이다.



```R
> #베리맥스 요인 회전법
> result <- factanal(subject, factors = 2, rotation="varimax")
> result

Call:
factanal(x = subject, factors = 2, rotation = "varimax")

Uniquenesses:
   s1    s2    s3    s4    s5    s6 
0.250 0.015 0.005 0.136 0.407 0.107 

Loadings:
   Factor1 Factor2
s1  0.862         
s2  0.988         
s3          0.997 
s4 -0.115   0.923 
s5 -0.692   0.338 
s6 -0.846   0.421 

               Factor1 Factor2
SS loadings      2.928   2.152
Proportion Var   0.488   0.359
Cumulative Var   0.488   0.847

Test of the hypothesis that 2 factors are sufficient.
The chi square statistic is 11.32 on 4 degrees of freedom.
The p-value is 0.0232 

```





##### 베리맥스 요인 회전법을 적용하여 요인 분석 수행 p-value는 0.0232로 유의수준 0.05보다 적기 때문에 요인수로 부족하다는 의미

```R
> result <- factanal(subject, factors=3, rotation="varimax" , scores="regression")
> result

Call:
factanal(x = subject, factors = 3, scores = "regression", rotation = "varimax")

Uniquenesses:
   s1    s2    s3    s4    s5    s6 
0.005 0.056 0.051 0.005 0.240 0.005 

Loadings:
   Factor1 Factor2 Factor3
s1 -0.379           0.923 
s2 -0.710   0.140   0.649 
s3  0.236   0.931   0.166 
s4  0.120   0.983  -0.118 
s5  0.771   0.297  -0.278 
s6  0.900   0.301  -0.307 

               Factor1 Factor2 Factor3
SS loadings      2.122   2.031   1.486
Proportion Var   0.354   0.339   0.248
Cumulative Var   0.354   0.692   0.940

The degrees of freedom for the model is 0 and the fit was 0.7745 

```





### 상관분석

- 요인분석 과정에서 변수들이 상관관계를 분석하여 변수 간의 관련성을 분석하는데 이용



### 회귀분석

- 인과관계를 분석하는데 중요한 자료를 제공



